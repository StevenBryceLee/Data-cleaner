{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to perform data cleaning on any given object which can be converted to a pandas dataframe Tasks\n",
    "\n",
    "Removal of unwanted observations by deleting duplicate or irrelevant values (two records with identical ids)\n",
    "\n",
    "Fixing Structural errors such as typos, misnaming (ie America and america as the list of countries)\n",
    "\n",
    "Managing unwanted outliers (Data points more than 3 standard deviations from the mean in a normal distribution)\n",
    "\n",
    "Handling missing data (Either drop or impute new data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle imports for processing and displaying data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner:\n",
    "    \"\"\"A class for cleaning databases\n",
    "    This class accepts a filepath as a string as input for\n",
    "    its constructor which represents the csv file to be loaded. \n",
    "    DataCleaner provides several methods for cleaning data, or \n",
    "    can be used as a default cleaner to apply basic \n",
    "    data transformations\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "     cols_to_drop: list\n",
    "        The string list of columns to be dropped by name\n",
    "    index_col: str\n",
    "        The index column of the dataframe\n",
    "    data: pandas.DataFrame\n",
    "        Data which needs to be cleaned\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cols_to_drop = []\n",
    "    index_col = ''\n",
    "    data = None\n",
    "    \n",
    "    #initialize DataCleaner with a string\n",
    "    def __init__(self, filePath = None, cols_to_drop = None, \n",
    "                 index_col = None, automate = False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        filePath : str\n",
    "            The filepath to the csv file\n",
    "        cols_to_drop: list\n",
    "            The string list of columns to be dropped by name\n",
    "        index_col: str\n",
    "            The index column of the dataframe\n",
    "        automate: bool\n",
    "            Whether or not to try and automatically clean the data\n",
    "            \n",
    "        \"\"\"\n",
    "        self.cols_to_drop = cols_to_drop\n",
    "        self.index_col = index_col\n",
    "        data = pd.read_csv(self.file_path)\n",
    "        if(index_col != None):\n",
    "            data.set_index(index_col, inplace = True)\n",
    "        if(cols_to_drop != None):\n",
    "            data.drop(cols_to_drop, inplace = True, axis = 1)\n",
    "        #Automatically clean the data if desired\n",
    "        if(automate):\n",
    "            transformColTypes(self,self.data)\n",
    "            handleNulls(self,self.data)\n",
    "            \n",
    "    def valueToNan(self,data,value,columns):\n",
    "        \"\"\"\n",
    "        This function converts values within columns to NaN and is used\n",
    "        for invalid values which have been marked as 0, null, etc\n",
    "        Parameters\n",
    "        ----------\n",
    "        data is a dataframe containing data\n",
    "        value is the invalid value\n",
    "        columns are the columns where the invalid value is located\n",
    "        \"\"\"\n",
    "        data[[columns]] = data[[columns]].replace(value,np.NaN)\n",
    "        \n",
    "    def getNulls(self,data):\n",
    "        return data.isnull().sum()\n",
    "    \n",
    "    def getInfo(self,data):\n",
    "        return self.data.info()\n",
    "    \n",
    "    def handleNulls(self, data):\n",
    "        \"\"\"\n",
    "        This function tries to fill null values, or drops columns with\n",
    "        more than 75% missing values. Drops rows with more than 75% \n",
    "        missing values\n",
    "        Parameters and gets \n",
    "        ---------\n",
    "        data is a dataframe containing data\n",
    "        \"\"\"\n",
    "        #Drop columns which have 90% NaN\n",
    "        self.data.dropna(thresh=int(data.shape[0] * .9), axis=1, inplace = True)\n",
    "        #Drop rows which have 90% NaN\n",
    "        self.data.dropna(thresh=int(data.shape[0] * .9), axis=0, inplace = True)\n",
    "        #use imputer to impute the rest of the null values with column mean\n",
    "        imputer = Imputer(missing_values = \"NaN\", strategy = \"mean\", axis = 1)\n",
    "        imputer = imputer.fit(self.data)\n",
    "        self.data = imputer.transform(self.data)\n",
    "    def transformColTypes(self, data):\n",
    "        \"\"\"\n",
    "        This function tries to impute column types from default dtypes\n",
    "        Parameters and gets \n",
    "        ---------\n",
    "        data is a dataframe containing data\n",
    "        \"\"\"\n",
    "        #First, try to infer data types to convert object type columns\n",
    "        self.data = data.infer_objects()\n",
    "        for column in data.columns:\n",
    "            #Test for conversion to categorical type, then get dummies\n",
    "            if(data[column].nunique() < 5):\n",
    "                try:\n",
    "                    data[column].astype('category')\n",
    "                except:\n",
    "                    continue\n",
    "                pd.get_dummies(self.data, prefix = column, drop_first = True)\n",
    "        \n",
    "    def getDataFrame(self):\n",
    "        return self.data\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
